{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3e2e566",
   "metadata": {},
   "source": [
    "## Section 1: PyTorch Basics and Training Loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6744b57",
   "metadata": {},
   "source": [
    "### Moving the device to the gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e7ab42",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Instantiation and MPS GPU Device Setup\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Device setup: MPS (for Mac), fallback to CPU\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\") #torch.backends.cuda for non mac\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Instantiate your model\n",
    "model = HandGestureCNN(num_classes=6).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b383b5f",
   "metadata": {},
   "source": [
    "### PyTorch Basics and Training Loops\n",
    "* nn.Module \n",
    "* nn.Sequential\n",
    "\n",
    "\n",
    "nn.Module: The base class for all neural networks in Pytorch. Ir organizes layers and parameters.\n",
    "\n",
    "nn.Sequential: A simpler way to stack layers in order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3a7364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=1, out_features=1, bias=True)\n",
      "weight: Parameter containing:\n",
      "tensor([[-0.5132]], requires_grad=True)\n",
      "Bias Parameter containing:\n",
      "tensor([0.8347], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Example: Building a linear model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a simple model\n",
    "linear_model = nn.Linear(1, 1) # 1 input feature 1 output feature\n",
    "print(linear_model)\n",
    "\n",
    "# Accessing parameters\n",
    "print(\"weight:\", linear_model.weight)\n",
    "print(\"Bias\", linear_model.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c5ee3e",
   "metadata": {},
   "source": [
    "### Optimizer and Loss Functions\n",
    "* Optimizers: Update model parameters based on gradients(e.g., SGD, ADAM)\n",
    "* Loss Functions: Measure how far predictions are from the target (e.g., MSELoss, CrossEntropyLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bc7e66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Defining Optimizer and Loss functions\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = optim.SGD(linear_model.parameters(), lr=0.01)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa111ccf",
   "metadata": {},
   "source": [
    "### Trainig loops \n",
    "\n",
    "* Steps:\n",
    "    - 1. Forward pass: Compute predictions.\n",
    "    - 2. Compute loss: Compare predictions to adjust weights.\n",
    "    - 3. Backward pass: Compute gradients.\n",
    "    - 4. Update paramenters: Use optimizer to adjust weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0f928d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 80.6839\n",
      "Epoch 10, Loss: 8.3697\n",
      "Epoch 20, Loss: 1.4517\n",
      "Epoch 30, Loss: 0.7622\n",
      "Epoch 40, Loss: 0.6672\n",
      "Epoch 50, Loss: 0.6302\n",
      "Epoch 60, Loss: 0.6000\n",
      "Epoch 70, Loss: 0.5718\n",
      "Epoch 80, Loss: 0.5449\n",
      "Epoch 90, Loss: 0.5193\n"
     ]
    }
   ],
   "source": [
    "# Example: Training Loop \n",
    "\n",
    "# sample data\n",
    "x_train = torch.tensor([[1.0],[2.0],[3.0]])\n",
    "y_train = torch.tensor([[4.0],[8.0],[12.0]])\n",
    "\n",
    "# Training loop\n",
    "n_epochs = 100\n",
    "for epoch in  range(n_epochs):\n",
    "    # Forward pass\n",
    "    y_pred = linear_model(x_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "    # Backward pass \n",
    "    optimizer.zero_grad()   #clears old gradients\n",
    "    loss.backward()         #computes new gradients via back propagations\n",
    "\n",
    "    # Update parameters\n",
    "    optimizer.step()        #updates the parameters using gradients\n",
    "\n",
    "    # Print loss evey 10 epochs\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\") #item() is a method used in PyTorch and NumPy for tensors or arrays that contain only one element. It is used to extract that single value as a standard Python scalar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c03256",
   "metadata": {},
   "source": [
    "## Section 2: Convolutional Neural Networks (CNNs):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f2b554",
   "metadata": {},
   "source": [
    "### 1. What are CNNs?\n",
    "* CNNs are specialized neural networks designed for processing structured grid data, such as images\n",
    "* They are widely used in computer vision tasks like image classification, object detection, and segmentation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc9b0a8",
   "metadata": {},
   "source": [
    "### 2. Key components of CNNs\n",
    "-   1. Convolution Layers (nn.Conv2d or nn.Conv3d):\n",
    "    * Extracts features from input images by applying filters (kernels).\n",
    "    * Each filter detects specific patterns like edges, textures, or shapes.\n",
    "    * Output: Feature maps"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e97a7bc8",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "nn.Conv2d(\n",
    "    in_channels,        # 🔢 required, position 1\n",
    "    out_channels,       # 🔢 required, position 2\n",
    "    kernel_size,        # 🔲 required, position 3 (can be int or tuple)\n",
    "    stride=1,           # optional keyword argument\n",
    "    padding=0,          # optional keyword argument\n",
    "    dilation=1,\n",
    "    groups=1,\n",
    "    bias=True,\n",
    "    padding_mode='zeros'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e658610",
   "metadata": {},
   "source": [
    "### Convolutional Neural Networks (CNNs)\n",
    "\n",
    "#### Key Components:\n",
    "1. **Convolutional Layers (`nn.Conv2d`)**: Extracts features from images.\n",
    "2. **Activation Functions (`nn.ReLU`)**: Introduce non-Linearity.\n",
    "3. **Pooling Layers (`nn.MaxPool2d`)**: Downsample feature maps. \n",
    "4. **Fully Connected Layers (`nn.Linear`)**: Combine features for predictions. \n",
    "5. **Dropout (`nn.Dropout`)**: Prevents overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1001bf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleCNN(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc): Linear(in_features=4096, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Example: Simple CNN\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a simple CNN \n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1) #Input: 3 channels, output: 16 channels\n",
    "        self.pool = nn.MaxPool2d(2) # Down sample by 2\n",
    "        self.fc = nn.Linear(16 * 16 * 16, 10) # Fully connected layer for 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.Relu()(self.conv1(x))) # Conv -> ReLU -> Pool\n",
    "        x = x.view(-1, 16 * 16 * 16) # Flatten\n",
    "        x = self.fc(x) # Fully connected Layer\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleCNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b445901",
   "metadata": {},
   "source": [
    "#### Training a CNN\n",
    "- Using the same training loop as before:\n",
    "1. Forward pass: Compute Prediction.\n",
    "2. Compute loss: Compare prediction to ground truth\n",
    "3. Backward pass: Compute gradients. \n",
    "4. Update parameters: Use optimizer to adjust the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abfb9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Training Loop for CNN\n",
    "\n",
    "# Sample data (random tensor for demonstration)\n",
    "x_train = torch.rand(8, 3, 32, 32) # Batch of 8 RGB images (3 channels, 32X32)\n",
    "y_train = torch.randint(0, 10, (8,))  # Batch of 8 labels (10 classes)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "n_epochs = 10\n",
    "for epoch in range(n_epochs):\n",
    "    # Forward pass\n",
    "    y_pred = model(x_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print loss every epoch\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003e9c57",
   "metadata": {},
   "source": [
    "### More advanced Architecture: \n",
    "This architecture has:\n",
    "* 3 convolutional blocks with increasing depth\n",
    "* Dropout before the classifier to reduce overfitting\n",
    "* Final fully connected layer with 6 outputs (1 per gesture class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2da347e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the model\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class HandGestureCNN(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(HandGestureCNN, self).__init__()\n",
    "        \n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1), #in_channels, out_channels, kernel_size, -OPTIONALS-> stride, padding, dilation, groups, bias, padding_mode='zeroes'\n",
    "            nn.BatchNorm2d(32),                         # in\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        # Assuming input size is 224x224 → after 3 pools (divided by 8) = 28x28\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(128 * 28 * 28, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.conv_block3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ea867f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the Optimizer and Loss Function\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# Loss function for multi-class classification\n",
    "#Label smoothing to cross entropy below #criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)  # 0.1 is a good starting point, helps prevent overconfidence\n",
    "\n",
    "# Adam optimizer with optional weight decay (L2 regularization)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a162897d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining scheduler after optimizer\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5, verbose=True)\n",
    "#This reduces LR by half if val loss doesn’t improve after 2 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d6853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAINING LOOP !!! Includes: \n",
    "    # Process tracking for training and validation, \n",
    "    # Saving the best model to checkpoints/best_model.pth\n",
    "    # Support both MPS or CPU\n",
    "\n",
    "import time\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=10, patience=3):\n",
    "    best_val_loss = float('inf')\n",
    "    no_improve_epochs = 0 #logic to automatically stop when overfitting while not watching the training, patience defaulted to 3\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': []\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        start_time = time.time()\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        epoch_train_loss = running_loss / len(train_loader.dataset)\n",
    "        history['train_loss'].append(epoch_train_loss)\n",
    "\n",
    "        #  Evaluate on validation set\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        epoch_val_loss = val_loss / len(val_loader.dataset)\n",
    "        epoch_val_acc = correct / total\n",
    "\n",
    "        history['val_loss'].append(epoch_val_loss)\n",
    "        history['val_acc'].append(epoch_val_acc)\n",
    "        \n",
    "        #  Save best model & check early stopping\n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            no_improve_epochs = 0\n",
    "\n",
    "            torch.save({\n",
    "                'model_state': model.state_dict(),\n",
    "                'optimizer_state': optimizer.state_dict()\n",
    "            }, 'checkpoints/full_checkpoint.pth')\n",
    "\n",
    "            torch.save(model.state_dict(), \"checkpoints/best_model.pth\")\n",
    "            print(f\"✅ Saved new best model at epoch {epoch+1}\")\n",
    "\n",
    "        else:\n",
    "            no_improve_epochs += 1\n",
    "            print(f\"⏳ No improvement for {no_improve_epochs} epoch(s)\")\n",
    "\n",
    "        #  Print epoch summary\n",
    "        duration = time.time() - start_time\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "              f\"Train Loss: {epoch_train_loss:.4f} | \"\n",
    "              f\"Val Loss: {epoch_val_loss:.4f} | \"\n",
    "              f\"Val Acc: {epoch_val_acc*100:.2f}% | \"\n",
    "              f\"Time: {duration:.1f}s\")\n",
    "        \n",
    "        scheduler.step(epoch_val_loss)## step the learning rate rescheduler\n",
    "#\n",
    "        if no_improve_epochs >= patience:\n",
    "            print(f\"🛑 Early stopping triggered after {epoch+1} epochs.\")\n",
    "            print(f\" Best model was at val loss: {best_val_loss:.4f}\")\n",
    "            break\n",
    "\n",
    "    return history\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ef6f48",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec62ee6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20  # todo: mess around with different number of epochs\n",
    "history = train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7fdd0d",
   "metadata": {},
   "source": [
    "### Section 3:  Recurrent Neural Networks (RNNs)\n",
    "\n",
    "1. What are RNNs?\n",
    "2. Key components of RNNs:\n",
    "    - Hidden states\n",
    "    - Sequence processing\n",
    "3. Building an RNN in PyTorch\n",
    "4. Training and evaluating an RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f48cc3",
   "metadata": {},
   "source": [
    "### Recurrent Neural Networks (RNNs)\n",
    "\n",
    "#### What are RNNs?\n",
    "- RNNs are a type of neural network designed for sequential data.\n",
    "- They process input sequences one step at a time, maintaining a **hidden state** that captures information about previous steps.\n",
    "- Common applications include:\n",
    "  - Time-series forecasting\n",
    "  - Natural Language Processing (NLP)\n",
    "  - Speech recognition\n",
    "\n",
    "#### Key Components of RNNs:\n",
    "1. **Hidden States**:\n",
    "   - RNNs maintain a hidden state that is updated at each time step.\n",
    "   - This allows them to capture temporal dependencies in the data.\n",
    "\n",
    "2. **Sequence Processing**:\n",
    "   - RNNs process sequences element by element, making them suitable for tasks where order matters.\n",
    "\n",
    "3. **Variants of RNNs**:\n",
    "   - **Vanilla RNN**: Basic RNN structure.\n",
    "   - **LSTM (Long Short-Term Memory)**: Handles long-term dependencies better by using gates.\n",
    "   - **GRU (Gated Recurrent Unit)**: A simplified version of LSTM with fewer parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83dccb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleRNN(\n",
      "  (rnn): RNN(1, 16, batch_first=True)\n",
      "  (fc): Linear(in_features=16, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Example: Simple RNN in PyTorch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a simple RNN\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, hidden = self.rnn(x)  # RNN layer\n",
    "        out = self.fc(out[:, -1, :])  # Fully connected layer (use last time step)\n",
    "        return out\n",
    "\n",
    "# Instantiate the model\n",
    "input_size = 1\n",
    "hidden_size = 16\n",
    "output_size = 1\n",
    "model = SimpleRNN(input_size, hidden_size, output_size)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444b2524",
   "metadata": {},
   "source": [
    "#### Training an RNN\n",
    "- Use the same training loop structure as before:\n",
    "  1. Forward pass: Compute predictions.\n",
    "  2. Compute loss: Compare predictions to ground truth.\n",
    "  3. Backward pass: Compute gradients.\n",
    "  4. Update parameters: Use optimizer to adjust weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66ffa1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcogod/Documents/Spring 25/CSC 360 Deep Learning/DeepLearning/csc360deeplearning/lib/python3.11/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 99, 1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5296\n",
      "Epoch 21, Loss: 0.5001\n",
      "Epoch 41, Loss: 0.5001\n",
      "Epoch 61, Loss: 0.5000\n",
      "Epoch 81, Loss: 0.5000\n",
      "Epoch 101, Loss: 0.5000\n",
      "Epoch 121, Loss: 0.5000\n",
      "Epoch 141, Loss: 0.5000\n",
      "Epoch 161, Loss: 0.5000\n",
      "Epoch 181, Loss: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Example: Training Loop for RNN\n",
    "\n",
    "# Sample data (sine wave for demonstration)\n",
    "import numpy as np\n",
    "x = np.linspace(0, 2 * np.pi, 100)\n",
    "y = np.sin(x)\n",
    "\n",
    "x_train = torch.tensor(y[:-1], dtype=torch.float32).view(1, -1, 1)  # Input sequence\n",
    "y_train = torch.tensor(y[1:], dtype=torch.float32).view(1, -1, 1)  # Target sequence\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "n_epochs = 200\n",
    "for epoch in range(n_epochs):\n",
    "    # Forward pass\n",
    "    y_pred = model(x_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print loss every 20 epochs\n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a645cc",
   "metadata": {},
   "source": [
    "#### LSTM and GRU\n",
    "- **LSTM (Long Short-Term Memory)**:\n",
    "  - Handles long-term dependencies using gates (input, forget, and output gates).\n",
    "  - More effective for tasks like text generation and time-series forecasting.\n",
    "\n",
    "- **GRU (Gated Recurrent Unit)**:\n",
    "  - A simplified version of LSTM with fewer parameters.\n",
    "  - Faster to train while still handling long-term dependencies.\n",
    "\n",
    "#### Example: LSTM in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "044c7864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleLSTM(\n",
      "  (lstm): LSTM(1, 16, batch_first=True)\n",
      "  (fc): Linear(in_features=16, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Example: LSTM in PyTorch\n",
    "\n",
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, (hidden, cell) = self.lstm(x)  # LSTM layer\n",
    "        out = self.fc(out[:, -1, :])  # Fully connected layer (use last time step)\n",
    "        return out\n",
    "\n",
    "# Instantiate the LSTM model\n",
    "model = SimpleLSTM(input_size, hidden_size, output_size)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fa3c227b",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Other modules in torch.nn besides nn.Linear and nn.Sequential, each serving different purposes depending on your model architecture. \n",
    "Here’s a quick breakdown of commonly used ones by category:\n",
    "\n",
    "🔢 Linear Layers\n",
    "\t•\tnn.Linear — fully connected layer (as discussed)\n",
    "\t•\tnn.Bilinear — bilinear transformation for two input tensors\n",
    "\t•\tnn.Identity — returns input as-is (useful for conditional architecture)\n",
    "\n",
    "🧠 Model Containers / Composition\n",
    "\t•\tnn.Sequential — chain modules in order\n",
    "\t•\tnn.ModuleList — store a list of modules (loop control is manual)\n",
    "\t•\tnn.ModuleDict — store a dictionary of modules (key access)\n",
    "\t•\tnn.ParameterList / nn.ParameterDict — for storing raw learnable parameters\n",
    "\n",
    "🔀 Activation Functions\n",
    "\t•\tnn.ReLU, nn.LeakyReLU, nn.ELU, nn.Sigmoid, nn.Tanh, etc.\n",
    "\t•\tnn.Softmax / nn.LogSoftmax — useful for multi-class classification\n",
    "\n",
    "📉 Loss Functions\n",
    "\t•\tnn.CrossEntropyLoss — for classification\n",
    "\t•\tnn.MSELoss — mean squared error\n",
    "\t•\tnn.BCELoss / nn.BCEWithLogitsLoss — for binary classification\n",
    "\t•\tnn.NLLLoss — negative log-likelihood loss (used with LogSoftmax)\n",
    "\n",
    "📐 Convolution Layers\n",
    "\t•\tnn.Conv1d, nn.Conv2d, nn.Conv3d\n",
    "\t•\tnn.ConvTranspose2d — for upsampling / decoding\n",
    "\n",
    "🧹 Normalization Layers\n",
    "\t•\tnn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d\n",
    "\t•\tnn.LayerNorm, nn.GroupNorm, nn.InstanceNorm2d\n",
    "\n",
    "📉 Dropout / Regularization\n",
    "\t•\tnn.Dropout, nn.Dropout2d, nn.AlphaDropout\n",
    "\n",
    "📏 Pooling Layers\n",
    "\t•\tnn.MaxPool1d, nn.MaxPool2d, nn.AdaptiveAvgPool2d, etc.\n",
    "\n",
    "🧾 Recurrent Layers\n",
    "\t•\tnn.RNN, nn.LSTM, nn.GRU\n",
    "\n",
    "🧮 Transformers & Attention\n",
    "\t•\tnn.MultiheadAttention\n",
    "\t•\tnn.Transformer, nn.TransformerEncoder, etc.\n",
    "\n",
    "🧰 Utility Layers\n",
    "\t•\tnn.Flatten — flattens input (e.g., from image to vector)\n",
    "\t•\tnn.Unflatten, nn.Reshape, nn.Permute (newer PyTorch)\n",
    "\t•\tnn.Embedding — for NLP\n",
    "\t•\tnn.EmbeddingBag — optimized embedding for bag-of-words\n",
    "\n",
    "If you tell me the type of model you’re building (CNN, transformer, classifier, etc.), I can recommend which modules are most relevant to your case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d74a380",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csc360deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
