{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marcos Hernandez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 4.220981945202209\n",
      "Epoch 100, Loss: 3.8177059409996374\n",
      "Epoch 200, Loss: 3.7107191777387123\n",
      "Epoch 300, Loss: 3.547962552191203\n",
      "Epoch 400, Loss: 3.3047682141058194\n",
      "Epoch 500, Loss: 2.9594849771411478\n",
      "Epoch 600, Loss: 2.5212676565064314\n",
      "Epoch 700, Loss: 2.058430650724251\n",
      "Epoch 800, Loss: 1.6703921372458186\n",
      "Epoch 900, Loss: 1.410707856657131\n",
      "Trainig complete.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "#loading data\n",
    "data= pd.read_csv(\"data.csv\")\n",
    "x= data[['x1','x2']].values\n",
    "y= data['y'].values.reshape(-1,1)\n",
    "\n",
    "# initializing model params\n",
    "np.random.seed(0)\n",
    "\n",
    "#input layer no W no B, only passes input data to 1st hidden layer\n",
    "\n",
    "#hidden layers\n",
    "\n",
    "#layer 1                  # 2 by 3\n",
    "W1 = np.random.randn(2,3) #2x3-> 2weights for 3neurons #weights for the first layer 2 inputs, 3 neurons\n",
    "                    \n",
    "b1= np.zeros((1,3)) #1x3-> 1bias for each neuron #setting Bias for the first layer neurons\n",
    "#Layer 2\n",
    "W2 = np.random.randn(3, 2) # 3 weights, for 500 neurons\n",
    "b2 = np.zeros((1,2))    # 1x2 -> a bias per neuron\n",
    "#Layer 3\n",
    "W3 = np.random.randn(2, 1) # w x n -> 500 incoming weights for 1 neuron\n",
    "b3 = np.zeros((1,1))     # 1 neuron\n",
    "\n",
    "#Activation function\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "#Derivative of the sigmoid function\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x)*(1-sigmoid(x))\n",
    "\n",
    "#Forward pass\n",
    "def forward(x):\n",
    "    z1 = np.dot(x, W1) + b1\n",
    "    a1 = sigmoid(z1)\n",
    "    z2 = np.dot(a1, W2) + b2\n",
    "    a2 = sigmoid(z2)\n",
    "    z3 = np.dot(a2, W3) + b3\n",
    "    y_pred = z3\n",
    "    return z1, a1, z2, a2, z3, y_pred\n",
    "\n",
    "#Loss function (MSE)\n",
    "def compute_loss(y_true, y_pred):\n",
    "    return np.mean((y_true-y_pred)**2)\n",
    "\n",
    "# Training loop\n",
    "learning_rate = 0.01\n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    #Forward pass\n",
    "    z1, a1, z2, a2, z3, y_pred = forward(x)\n",
    "\n",
    "    #compute loss\n",
    "    loss = compute_loss(y,y_pred) #y is dataset target\n",
    "\n",
    "    #Backwards pass                #y.shape[0]\n",
    "    dL_dy_pred= 2 * (y_pred - y) / y.shape[0] #size(0)  #derivative of loss for prediciton\n",
    "    #dL_dz3 = dL_dy_pred * sigmoid_derivative(z3)###whyyyy### Not needed for regression\n",
    "    dL_dw3 = np.dot(a2.T, dL_dy_pred)\n",
    "    dL_db3 = np.sum(dL_dy_pred, axis=0, keepdims=True)# ,keepdims = True\n",
    "\n",
    "    dL_da2 = np.dot(dL_dy_pred, W3.T)       # derivative of the loss for for a2, activaiton func of 2nd layer\n",
    "    dL_dz2 = dL_da2 * sigmoid_derivative(z2)\n",
    "    dL_dw2 = np.dot(a1.T, dL_dz2)\n",
    "    dL_db2 = np.sum(dL_dz2, axis=0, keepdims=True)\n",
    "\n",
    "    dL_da1 = np.dot(dL_dz2, W2.T)\n",
    "    dL_dz1 = dL_da1 * sigmoid_derivative(z1)\n",
    "    dL_dw1 = np.dot(x.T,dL_dz1)\n",
    "    dL_db1 = np.sum(dL_dz1, axis=0, keepdims=True)\n",
    "\n",
    "    #updating parameters\n",
    "    W3 -= learning_rate * dL_dw3\n",
    "    b3 -= learning_rate * dL_db3\n",
    "    W2 -= learning_rate * dL_dw2\n",
    "    b2 -= learning_rate * dL_db2\n",
    "    W1 -= learning_rate * dL_dw1\n",
    "    b1 -= learning_rate * dL_db1\n",
    "\n",
    "    #printing loss every 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss}')\n",
    "\n",
    "print(\"Trainig complete.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brainstorming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')  # MPS for Metal Performance Shaders\n",
    "    print('device set to mps')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('device set to cuda')\n",
    "    print(\"cuda\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"device set to cpu\")\n",
    "tensor = torch.randn(3, 3, device=device)\n",
    "\n",
    "print(tensor)\n",
    "\n",
    "print(tensor.ndim) # number of dimensions\n",
    "\n",
    "rand_tensor = torch.randn(3,4,2, device= device)\n",
    "print(rand_tensor)\n",
    "print(\"rand tens ndim\", rand_tensor.ndim) \n",
    "\n",
    "print(rand_tensor[0,0,1]) #indexing\n",
    "print(rand_tensor.size()) # .size() method\n",
    "print(rand_tensor.shape) #.shape object\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csc360deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
